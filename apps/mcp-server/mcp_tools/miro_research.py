import asyncio
import logging
from typing import Any, List, Dict, Set

from mcp_config import Config
from llm_client import LLMClient
from mcp_tools.miro_search import _raw_search
from mcp_tools.miro_read import do_miro_read

logger = logging.getLogger("mirothinker")

RESEARCH_PLAN_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚ç”¨æˆ·æƒ³ç ”ç©¶ä»¥ä¸‹è¯é¢˜ï¼š

ç ”ç©¶è¯é¢˜: {question}

è¯·è§„åˆ’ä¸€ç³»åˆ—æœç´¢æŸ¥è¯¢æ¥å¸®åŠ©ç ”ç©¶è¿™ä¸ªè¯é¢˜ã€‚è¯·ä»¥ JSON æ ¼å¼è¿”å›æœç´¢æŸ¥è¯¢åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "search_queries": [
    "ç¬¬ä¸€ä¸ªæœç´¢æŸ¥è¯¢",
    "ç¬¬äºŒä¸ªæœç´¢æŸ¥è¯¢",
    "ç¬¬ä¸‰ä¸ªæœç´¢æŸ¥è¯¢",
    "ç¬¬å››ä¸ªæœç´¢æŸ¥è¯¢",
    "ç¬¬äº”ä¸ªæœç´¢æŸ¥è¯¢"
  ]
}}

æœ€å¤šè¿”å› 5 ä¸ªæœç´¢æŸ¥è¯¢ï¼Œè¦ä»ä¸åŒè§’åº¦è¦†ç›–è¿™ä¸ªè¯é¢˜ã€‚"""

ANALYZE_RESULTS_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚æˆ‘ä»¬æ­£åœ¨ç ”ç©¶ä»¥ä¸‹è¯é¢˜ï¼š

ç ”ç©¶è¯é¢˜: {question}

å·²æ”¶é›†çš„ä¿¡æ¯æ‘˜è¦:
{findings_summary}

è¯·åˆ†æè¿™äº›ä¿¡æ¯ï¼Œä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼š
1. å½“å‰ä¿¡æ¯è¦†ç›–äº†å“ªäº›æ–¹é¢ï¼Ÿï¼ˆæŠ€æœ¯ã€å•†ä¸šã€ç›‘ç®¡ã€æ¡ˆä¾‹ç­‰ï¼‰
2. è¿˜ç¼ºå°‘å“ªäº›å…³é”®æ–¹é¢ï¼Ÿ
3. å·²æœ‰ä¿¡æ¯ä¹‹é—´æ˜¯å¦æœ‰çŸ›ç›¾éœ€è¦éªŒè¯ï¼Ÿ
4. è¯·ç”Ÿæˆé’ˆå¯¹å…·ä½“ç¼ºå¤±æ–¹é¢çš„è¡¥å……æœç´¢è¯
5. å¦‚æœæœ‰ç‰¹åˆ«æœ‰ä»·å€¼ä½†æ‘˜è¦å¤ªçŸ­çš„ URLï¼Œè¯·å»ºè®®æ·±å…¥é˜…è¯»

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{{
  "is_sufficient": true/false,
  "confidence": 0-100,
  "covered_aspects": ["å·²è¦†ç›–çš„æ–¹é¢1", "æ–¹é¢2"],
  "missing_aspects": ["ç¼ºå¤±çš„æ–¹é¢1", "æ–¹é¢2"],
  "contradictions": ["çŸ›ç›¾ç‚¹1"],
  "further_search_queries": ["é’ˆå¯¹ç¼ºå¤±æ–¹é¢çš„æœç´¢è¯1", "æœç´¢è¯2", "æœç´¢è¯3"],
  "urls_to_deep_read": ["éœ€è¦æ·±å…¥é˜…è¯»çš„URL1"]
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

SYNTHESIZE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚è¯·ç»¼åˆä»¥ä¸‹ç ”ç©¶ç»“æœï¼š

ç ”ç©¶è¯é¢˜: {question}

æ”¶é›†åˆ°çš„ä¿¡æ¯:
{all_info}

è¯·æ•´ç†ä¸€ä¸ªæ¸…æ™°çš„ç ”ç©¶æ€»ç»“ï¼Œæ ¼å¼è¯·å‚è€ƒï¼š
## å…³é”®å‘ç°
1. [å‘ç°å†…å®¹] â€” æ¥æº: [URL]
2. ...

## å„ä¿¡æ¯æºè¯¦æƒ…
### æ¥æº: [æ ‡é¢˜] ([URL])
[å†…å®¹]

---
### æŸ¥è¯¢è¿‡ç¨‹ç»Ÿè®¡
- æœç´¢è½®æ•°: X
- æœç´¢å…³é”®è¯: X ä¸ª
- è®¿é—®ç½‘é¡µ: X ä¸ª
- æœ‰æ•ˆä¿¡æ¯æº: X ä¸ª

### ä¿¡æ¯æ¥æº
1. [æ ‡é¢˜](URL)
2. ..."""


async def do_miro_research(
    config: Config,
    llm_client: LLMClient,
    question: str,
    max_rounds: int = 5,
    ctx: Any = None,
) -> str:
    if ctx:
        ctx.info(f"[MiroThinker] ğŸ”¬ å¼€å§‹ç³»ç»Ÿæ€§ç ”ç©¶: {question}")
        ctx.report_progress(0, max_rounds)
        ctx.info("[MiroThinker] ğŸ§  æ­£åœ¨åˆ†æç ”ç©¶é—®é¢˜...")

    all_findings: List[Dict] = []
    all_sources: List[Dict] = []
    visited_urls: Set[str] = set()
    search_count = 0
    read_count = 0
    search_queries_used: List[str] = []

    for round_num in range(max_rounds):
        if ctx:
            ctx.info(f"[MiroThinker] ğŸ”„ ç ”ç©¶è½®æ¬¡ {round_num + 1}/{max_rounds}")
            ctx.report_progress(round_num + 1, max_rounds)

        urls_to_deep_read = []

        if round_num == 0:
            plan_result = await llm_client.chat_json(
                RESEARCH_PLAN_PROMPT.format(question=question),
                role="main",
                temperature=0.7,
            )
            search_queries = plan_result.get("search_queries", [question])
            if ctx:
                ctx.info(f"[MiroThinker] ğŸ“‹ ç ”ç©¶è®¡åˆ’: å°†æœç´¢ {len(search_queries)} ä¸ªå…³é”®è¯")
        else:
            findings_list = []
            for f in all_findings[:15]:
                finding = f.get("finding", "")
                if len(finding) > 200:
                    finding = finding[:200] + "..."
                findings_list.append(f"- {finding}")
            findings_summary = "\n".join(findings_list)

            if ctx:
                ctx.info(f"[MiroThinker] ğŸ¤” æ­£åœ¨è¯„ä¼°å·²æ”¶é›†çš„ {len(all_findings)} æ¡ä¿¡æ¯...")

            analyze_result = await llm_client.chat_json(
                ANALYZE_RESULTS_PROMPT.format(
                    question=question, findings_summary=findings_summary
                ),
                role="main",
                temperature=0.7,
            )

            if analyze_result.get("is_sufficient", False):
                confidence = analyze_result.get("confidence", 0)
                if confidence >= 70:
                    if ctx:
                        ctx.info(f"[MiroThinker] âœ… ä¿¡æ¯å·²å……åˆ†({confidence}%)ï¼Œæå‰ç»“æŸç ”ç©¶")
                    break

            if ctx:
                missing = analyze_result.get("missing_aspects", [])
                if missing:
                    ctx.info(f"[MiroThinker] ğŸ“Š ç¼ºå°‘: {', '.join(missing)}")

            search_queries = analyze_result.get("further_search_queries", [f"{question} è¡¥å……ä¿¡æ¯"])
            urls_to_deep_read = analyze_result.get("urls_to_deep_read", [])

        for url in urls_to_deep_read:
            if url in visited_urls:
                continue
            visited_urls.add(url)
            read_count += 1
            try:
                if ctx:
                    ctx.info(f"[MiroThinker] ğŸ“– æ·±å…¥é˜…è¯»: {url}")
                read_result = await do_miro_read(
                    config, llm_client, url, query=question, ctx=ctx
                )
                title = url
                all_sources.append({"url": url, "title": title, "content": read_result})
                content_preview = read_result[:300].replace("\n", " ")
                all_findings.append({
                    "finding": content_preview,
                    "source_url": url
                })
            except Exception as e:
                logger.warning(f"Failed to deep read {url}: {e}")
                continue

        for query in search_queries[:3]:
            search_count += 1
            search_queries_used.append(query)

            search_results = await _raw_search(config, query, num_results=5, ctx=ctx)

            urls_to_read = []
            for item in search_results:
                url = item.get("link", "")
                if url and url not in visited_urls:
                    urls_to_read.append(url)

            for url in urls_to_read[:3]:
                if url in visited_urls:
                    continue
                visited_urls.add(url)
                read_count += 1

                try:
                    read_result = await do_miro_read(
                        config, llm_client, url, query=question, ctx=ctx
                    )
                    title = next((item.get("title", url) for item in search_results if item.get("link") == url), url)
                    all_sources.append({"url": url, "title": title, "content": read_result})

                    content_preview = read_result[:300].replace("\n", " ")
                    all_findings.append({
                        "finding": content_preview,
                        "source_url": url
                    })
                except Exception as e:
                    logger.warning(f"Failed to read {url}: {e}")
                    continue

        await asyncio.sleep(1)

    if ctx:
        ctx.info("[MiroThinker] ğŸ“Š æ­£åœ¨ç»¼åˆç ”ç©¶ç»“æœ...")

    all_info_text = "\n\n".join(
        [f"æ¥æº {i+1}: {s.get('title', s['url'])}\n{s['content']}" for i, s in enumerate(all_sources)]
    )

    final_summary = await llm_client.chat(
        SYNTHESIZE_PROMPT.format(question=question, all_info=all_info_text),
        role="main",
        temperature=0.3,
        max_tokens=8192,
    )

    stats_section = f"""
---
### æŸ¥è¯¢è¿‡ç¨‹ç»Ÿè®¡
- æœç´¢è½®æ•°: {min(round_num + 1, max_rounds)}
- æœç´¢å…³é”®è¯: {search_count} ä¸ª
- è®¿é—®ç½‘é¡µ: {read_count} ä¸ª
- æœ‰æ•ˆä¿¡æ¯æº: {len(all_sources)} ä¸ª

### ä¿¡æ¯æ¥æº
"""
    for i, s in enumerate(all_sources, 1):
        stats_section += f"{i}. [{s.get('title', s['url'])}]({s['url']})\n"

    if ctx:
        ctx.report_progress(max_rounds, max_rounds)
        ctx.info("[MiroThinker] âœ… ç ”ç©¶å®Œæˆ")

    return f"## è°ƒæŸ¥ç»“æœ: {question}\n\n{final_summary}\n{stats_section}"
